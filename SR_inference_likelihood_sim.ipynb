{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood: -48.77909548935698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhonghou/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:213: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max alpha, gamma: (0.5500000000000003, 0.9900000000000007)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import learn\n",
    "import util\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy as sp\n",
    "import scipy.spatial.distance as dist\n",
    "import sys\n",
    "sys.path.append ('/Users/Zhonghou/Desktop/General/Preston Lab/tesser_successor')\n",
    "\n",
    "from tesser import network\n",
    "\n",
    "nodes = network.node_info()\n",
    "adjacency = network.adjacency (nodes)\n",
    "transition = adjacency / 6\n",
    "\n",
    "\n",
    "# makes the envstep necessary for learn.py\n",
    "def make_envstep (directory):\n",
    "    envstep = []\n",
    "    objects = util.get_objects (directory)\n",
    "    for index in range (len (objects)):\n",
    "        obj = objects.iat[index,0]\n",
    "        try:\n",
    "            envstep.append (int(obj))\n",
    "        except:\n",
    "            pass\n",
    "    return envstep\n",
    "\n",
    "def copy (list0):\n",
    "    list1 = []\n",
    "    for index in range (len(list0)):\n",
    "        list1.append (list0[index])\n",
    "    return list1\n",
    "\n",
    "def explore_runs (option, alpha, gamma, obj_sequence_directory):\n",
    "    \n",
    "    SR_matrices = []\n",
    "    \n",
    "    # This loop adds the address, part number and run number to the runs array, so that the object\n",
    "    #     sequence in each run can be inputted to the learning agent.\n",
    "    runs = []\n",
    "    directory = obj_sequence_directory\n",
    "    for part_num in [1]:\n",
    "        for run_num in [1,2,3,4,5]:\n",
    "            filename = 'tesserScan_100_B_StructLearn_Part%s_Run_%s.txt'%(part_num, run_num)\n",
    "            runs.append ([directory+filename, part_num, run_num])\n",
    "    \n",
    "    # This option allows the SR matrix to persist across all runs from Part 1 and Part 2\n",
    "    #     without ever resetting.\n",
    "    if option == 'persist':\n",
    "        M = np.zeros([21,21])\n",
    "        for run in runs:\n",
    "            part_num, run_num = run[1], run[2]\n",
    "            envstep = make_envstep (run[0])\n",
    "            M = np.array(learn.run_experiment(envstep, gamma, alpha, copy(M)))\n",
    "            SR_matrices.append (M)\n",
    "            \n",
    "    if option == 'repeat':\n",
    "        M = np.zeros([21,21])\n",
    "        for time in range (100):\n",
    "            for run in runs:\n",
    "                part_num, run_num = run[1], run[2]\n",
    "                envstep = make_envstep (run[0])\n",
    "                M = np.array (learn.run_experiment (envstep, gamma, alpha, copy(M)))\n",
    "        return M\n",
    "    \n",
    "    if option == 'once':\n",
    "        M = np.zeros([21,21])\n",
    "        for run in runs:\n",
    "            part_num, run_num = run[1], run[2]\n",
    "            envstep = make_envstep (run[0])\n",
    "            M = np.array (learn.run_experiment (envstep, gamma, alpha, copy(M)))\n",
    "        return M\n",
    "    \n",
    "    # This option allows the SR matrix to persist in Part 1 and Part 2, but resets it between them.\n",
    "    if option == 'reset':\n",
    "        M = np.zeros ([21,21])\n",
    "        is_reset = False\n",
    "        for run in runs:\n",
    "            part_num, run_num = run[1], run[2]\n",
    "            if not is_reset and part_num == 2:\n",
    "                M = np.zeros ([21,21])\n",
    "                is_reset = True\n",
    "            envstep = make_envstep (run[0])\n",
    "            M = np.array(learn.run_experiment(envstep, gamma, alpha, copy(M)))\n",
    "            SR_matrices.append (M)\n",
    "    \n",
    "    # This option resets the SR matrix between each run.\n",
    "    if option == 'independent':\n",
    "        for run in runs:\n",
    "            part_num, run_num = run[1], run[2]\n",
    "            M = np.zeros([21,21])\n",
    "            envstep = make_envstep (run[0])\n",
    "            M = learn.run_experiment(envstep, gamma, alpha, M)\n",
    "            SR_matrices.append (M)\n",
    "\n",
    "    # This option forces the SR matrix to persist across all runs, but instead of plotting the SR matrix\n",
    "    #     after each run, it plots the changes made to it after learning each object sequence.\n",
    "    if option == 'track changes':\n",
    "        M = np.zeros([21,21])\n",
    "        for run in runs:\n",
    "            part_num, run_num = run[1], run[2]\n",
    "            envstep = make_envstep (run[0])\n",
    "            M_new = np.copy(M)\n",
    "            M_new = learn.run_experiment(envstep, gamma, alpha, M_new)\n",
    "            SR_matrices.append (M)\n",
    "            M = M_new\n",
    "            \n",
    "    return SR_matrices\n",
    "\n",
    "# Modify the option in the following call to the main function in order to visualize the desired learning\n",
    "#     sequence.\n",
    "# explore_runs('track changes')\n",
    "\n",
    "# df.loc[[4,17],'connect'] = 1\n",
    "# df.loc[[3,11],'connect'] = 2\n",
    "# df.loc[[10,18],'connect'] = 3\n",
    "\n",
    "class Node:\n",
    "    comm = {1:[1,2,3,18,19,20,21],\n",
    "            2:[4,5,6,7,8,9,10],\n",
    "            3:[11,12,13,14,15,16,17]}\n",
    "    \n",
    "    def __init__ (self, index):\n",
    "        self.index = index\n",
    "        self.connections = []\n",
    "    \n",
    "    def update_connections (self):\n",
    "        if self.index == 4:\n",
    "            self.connections = [5,6,7,8,9,17]\n",
    "        elif self.index == 17:\n",
    "            self.connections = [12,13,14,15,16,4]\n",
    "        elif self.index == 3:\n",
    "            self.connections = [1,2,19,20,21,11]\n",
    "        elif self.index == 11:\n",
    "            self.connections = [12,13,14,15,16,3]\n",
    "        elif self.index == 10:\n",
    "            self.connections = [5,6,7,8,9,18]\n",
    "        elif self.index == 18:\n",
    "            self.connections = [1,2,19,20,21,10]\n",
    "        else:\n",
    "            for i in range (3):\n",
    "                if self.index in Node.comm[i+1]:\n",
    "                    self.connections = copy(Node.comm[i+1])\n",
    "                    self.connections.remove (self.index)\n",
    "            \n",
    "\n",
    "def compute_limit_matrix (gamma):\n",
    "    num_states = 21\n",
    "    identity = np.eye (num_states)\n",
    "    return np.linalg.inv (identity - gamma*adjacency/6)\n",
    "\n",
    "def rda (matrix):\n",
    "    return dist.squareform (dist.pdist (matrix, 'correlation'))\n",
    "\n",
    "def correlate_rows (matrix):\n",
    "    return np.dot(matrix, matrix.T) / (la.norm (matrix)**2)\n",
    "\n",
    "def correlate_columns (matrix):\n",
    "    return np.dot(matrix.T, matrix) / (la.norm (matrix)**2)\n",
    "\n",
    "def pBGivenA (A, B, C, SR):\n",
    "    return SR[A][B] / (SR[A][B] + SR[A][C])\n",
    "\n",
    "def pCGivenA (A, B, C, SR):\n",
    "    return 1 - pBGivenA (A, B, C, SR)\n",
    "\n",
    "def likelihood (cue, opt1, opt2, response, SR):\n",
    "    if response == 0:\n",
    "        return pBGivenA (cue, opt1, opt2, SR)\n",
    "    if response == 1:\n",
    "        return pCGivenA (cue, opt1, opt2, SR)\n",
    "\n",
    "def compute_correlations(option, alpha):\n",
    "    L = compute_limit_matrix (.5)\n",
    "    L_vector = L.flatten()\n",
    "    M = explore_runs ('repeat')\n",
    "    M_vector = M.flatten()\n",
    "    plt.matshow (M, vmin = 0, vmax = .5)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    if option == 'norm':\n",
    "        print ('Norm of L - M: ')\n",
    "        print (la.norm(L_vector - M_vector, np.inf))\n",
    "    \n",
    "    if option == 'correlation':\n",
    "        print ('Correlation of L, M: ')\n",
    "        print (np.dot (L_vector, M_vector) / (la.norm (L_vector) * la.norm (M_vector)))\n",
    "        \n",
    "    plt.matshow (L, vmin = 0, vmax = .5)\n",
    "    plt.colorbar()\n",
    "    \n",
    "# This function gives the probability of obtaining the choices in the run, given\n",
    "#     specific values for alpha, gamma.\n",
    "    \n",
    "# For obj_sequence_directory, enter the folder where the runs, which give the object sequence,\n",
    "#     are stored. Use tesser scan 100B. For induction_directory, enter the full path of the \n",
    "#     induction data.\n",
    "\n",
    "def get_log_likelihood(alpha, gamma, obj_sequence_directory, induction_directory):\n",
    "    SR = explore_runs ('once', alpha, gamma, obj_sequence_directory)\n",
    "    directory = induction_directory\n",
    "    cue_sequence, opt1_sequence, opt2_sequence, response_sequence = util.get_induction_data (directory)\n",
    "    num_trials = len (cue_sequence)\n",
    "    log_likelihood = 0\n",
    "    for trial_num in range (num_trials):\n",
    "        try:\n",
    "            cue_num, opt1_num, opt2_num, response_num = int(cue_sequence[trial_num]) - 1, int(opt1_sequence[trial_num]) - 1, int(opt2_sequence[trial_num]) - 1, int(response_sequence[trial_num]) - 1\n",
    "            trial_probability = likelihood (cue_num, opt1_num, opt2_num, response_num, SR)\n",
    "            log_likelihood += np.log (trial_probability)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "# This function finds alpha, gamma that maximize the likelihood function given by \n",
    "#     get_log_likelihood.\n",
    "\n",
    "# For obj_sequence_directory, enter the folder where the runs, which give the object sequence,\n",
    "#     are stored. Use tesser scan 100B. For induction_directory, enter the full path of the \n",
    "#     induction data.\n",
    "\n",
    "def maximize_likelihood (obj_sequence_directory, induction_directory):\n",
    "    h = 10e-3\n",
    "    alpha_max, gamma_max = 0.0, 0.0\n",
    "    alpha, gamma = h, h\n",
    "    log_likelihood_max = get_log_likelihood (alpha, gamma, obj_sequence_directory, induction_directory)\n",
    "    log_likelihoods = []\n",
    "    \n",
    "    \n",
    "    while alpha <= 1:\n",
    "        gamma = h\n",
    "        while gamma <= 1:\n",
    "            log_likelihood = get_log_likelihood(alpha, gamma, obj_sequence_directory, induction_directory)\n",
    "            log_likelihoods.append (log_likelihood)\n",
    "            if log_likelihood > log_likelihood_max:\n",
    "                log_likelihood_max = log_likelihood\n",
    "                alpha_max, gamma_max = alpha, gamma\n",
    "            gamma += h\n",
    "        alpha += h\n",
    "    \n",
    "    return alpha_max, gamma_max\n",
    "    \n",
    "# Format for the two functions below: \n",
    "# get_log_likelihood(alpha, gamma, obj_sequence_directory, induction_directory)\n",
    "# maximize_likelihood(obj_sequence_directory, induction_directory)\n",
    "\n",
    "# For obj_sequence_directory, enter the folder where the runs, which give the object sequence,\n",
    "#     are stored. Use tesser scan 100B. For induction_directory, enter the full path of the \n",
    "#     induction data.\n",
    "\n",
    "obj_sequence_directory = '/Users/Zhonghou/Desktop/General/Preston Lab/tesser_successor/tesserScan_100_B/'\n",
    "induction_directory = '/Users/Zhonghou/Desktop/General/Preston Lab/tesser_successor/tesserScan_100_B/tesserScan_100_B_InductGen.txt'\n",
    "alpha, gamma = .6, 1\n",
    "\n",
    "print ('Log likelihood:', get_log_likelihood (alpha, gamma, obj_sequence_directory, induction_directory))\n",
    "print ('Max alpha, gamma:', maximize_likelihood(obj_sequence_directory, induction_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
