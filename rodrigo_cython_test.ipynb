{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for testing and exploring objectives in tesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy import optimize\n",
    "from tesser import network\n",
    "from tesser import util\n",
    "from tesser import sr\n",
    "from tesser import fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/rodrigo/Dropbox/tesser_successor/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = util.load_struct_subject(data_dir, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 µs ± 1.07 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sr.clearn_sr(x, 0.5, 0.5,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert function to cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "induct_all = util.load_induct(data_dir)\n",
    "struct_all = util.load_struct(data_dir)\n",
    "\n",
    "subj_filter = f'SubjNum == {101}'\n",
    "induct_df = induct_all.query(subj_filter)\n",
    "struct_df = struct_all.query(subj_filter)\n",
    "\n",
    "n_states = len(np.unique(struct_df.objnum))\n",
    "\n",
    "# get community matrix\n",
    "net = network.temp_node_info()\n",
    "comm = 1 - distance.squareform(distance.pdist(net['comm'][:, None], 'hamming'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now to attempt fixing fitting times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_bounds(var_bounds, var_names):\n",
    "    \"\"\"Pack group-level parameters.\"\"\"\n",
    "\n",
    "    group_lb = [var_bounds[k][0] for k in var_names]\n",
    "    group_ub = [var_bounds[k][1] for k in var_names]\n",
    "    bounds = optimize.Bounds(group_lb, group_ub)\n",
    "    return bounds\n",
    "\n",
    "    \n",
    "def fit_induct(struct_df, induct_df, fixed, var_names, var_bounds, n_states,\n",
    "               f_optim=optimize.differential_evolution,\n",
    "               verbose=False, options=None, comm=[]):\n",
    "    \"\"\"Fit induction data for one subject.\n",
    "\n",
    "    For a given set of parameters, the structure learning task is used\n",
    "    to generate a simulated SR matrix. Then this matrix is used to \n",
    "    simulate responses in the induction task. Parameters are optimized\n",
    "    to obtain the set that maximizes the probability of the responses\n",
    "    observed in the induction task.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    struct_df : DataFrame\n",
    "        Structure learning data.\n",
    "\n",
    "    induct_df : DataFrame\n",
    "        Induction test data.\n",
    "\n",
    "    fixed : dict\n",
    "        Parameter values for all fixed parameters.\n",
    "\n",
    "    var_names : list\n",
    "        String name for each variable parameter.\n",
    "\n",
    "    var_bounds : dict\n",
    "        Bounds (in low, high order) for each variable parameter.\n",
    "\n",
    "    f_optim : function\n",
    "        Function to use for parameter optimization.\n",
    "\n",
    "    verbose : Boolean\n",
    "        If true, more information about the search will be printed.\n",
    "\n",
    "    options : dict\n",
    "        Options to pass to f_optim.\n",
    "\n",
    "    use_run : tuple\n",
    "        Run to take the SR matrix from for predicting induction data,\n",
    "        specified as (part_number, run_number).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    param : dict\n",
    "        Best-fitting parameters.\n",
    "\n",
    "    logl : float\n",
    "        Maximum log likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    if options is None:\n",
    "        options = {}\n",
    "\n",
    "    param = fixed.copy()\n",
    "    subjects = struct_df.SubjNum.unique()\n",
    "\n",
    "    def f_fit(x):\n",
    "        param.update(dict(zip(var_names, x)))\n",
    "        # draft code to fit at the group level:\n",
    "        logl = 0\n",
    "        for subject in subjects:\n",
    "            subj_filter = f'SubjNum == {subject}'\n",
    "            subj_struct = struct_df.query(subj_filter)\n",
    "            subj_induct = induct_df.query(subj_filter)\n",
    "            subj_logl = fit.cmain(subj_struct,subj_induct, **param, n_states=n_states,\n",
    "                                                     return_trial=False, comm=comm)\n",
    "            logl += subj_logl\n",
    "        # logl = get_induction_log_likelihood(struct_df, induct_df, **param,\n",
    "        #                                     return_trial=False, use_run=use_run)\n",
    "        return -logl\n",
    "\n",
    "    bounds = param_bounds(var_bounds, var_names)\n",
    "    res = f_optim(f_fit, bounds, disp=verbose, **options)\n",
    "\n",
    "    # fitted parameters\n",
    "    param = fixed.copy()\n",
    "    param.update(dict(zip(var_names, res['x'])))\n",
    "\n",
    "    logl = -res['fun']\n",
    "    return param, logl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'w': 1.0,\n",
       "  'gamma': 0.9915182972903186,\n",
       "  'alpha': 0.04573502900941932,\n",
       "  'tau': 1.0664064743190262},\n",
       " -1053.598065597301)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed = {'w': 1.0}\n",
    "var_names = ['gamma', 'alpha', 'tau']\n",
    "var_bounds = {'alpha': [0, 1], 'gamma': [0, 1], 'tau': [0, 10]}\n",
    "fit_induct(struct_all, induct_all, fixed, var_names, var_bounds, \n",
    "           n_states=n_states, verbose=False, comm=comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-28.89193189195182, <MemoryView of 'ndarray' at 0x7f1cdad67890>)\n"
     ]
    }
   ],
   "source": [
    "print(fit.cmain(struct_df, induct_df, 0.99, 0.02, 1.0, 1.0,n_states, True, comm=comm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0020296573638916016 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "fit.cmain(struct_df, induct_df, 0.5, 0.5, 0.5, 1.0, n_states, True, comm=comm)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.04805946350097656 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time =time.time()\n",
    "fit.get_induction_log_likelihood_hybrid(struct_df, induct_df, 0.5, 0.5, 0.5, 1.0)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39 ms ± 55.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fit.cmain(struct_df, induct_df, 0.5, 0.5, 0.5, 1.0, n_states, True, comm=comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 2s ± 8.57 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fit_induct(struct_all, induct_all, fixed, var_names, var_bounds,n_states=n_states, verbose=False, comm=comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
